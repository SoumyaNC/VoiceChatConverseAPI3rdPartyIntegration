<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Voice Chat Assistant</title>
  <style>

  </style>
  <link rel="stylesheet" href="site.css"  ></link>
</head>
<body>

  <div id="chat-container">
    <div class="chat-header">
      Voice Chat Assistant
      <span class="status">‚óè Online</span>
    </div>
    
    <div id="chat"></div>

    <div id="controls">
      <button id="start">üé§ Call</button>
      <button id="stop" disabled>üî¥ Drop</button>
    </div>
  </div>

  <script>
    const chat = document.getElementById('chat');
    let socket, audioContext, processor, mediaStream, source;

    let audioQueue = [];
    let isPlaying = false;
    let currentSource = null; 

    function scrollToBottom() {
      chat.scrollTop = chat.scrollHeight;
    }

    function appendMessage(text, sender,questionid=null, typingEffect = false, callback = null,) {
      const msg = document.createElement('div');
      msg.className = `msg ${sender}`;
      const agentDiv= document.getElementById(questionid);
      // alert(questionid);
      // alert(agentDiv);
      let bubble = document.createElement('div');
      if (agentDiv != undefined && agentDiv != null)
       {
          bubble=agentDiv;
       }
       
       if (text == '.....' )
       {
        const botMsg = document.createElement('p');
        botMsg.textContent=text;
        botMsg.classList.add('ripple');

        var div=`<div class="typing">
                  <div class="dot"></div>
                  <div class="dot"></div>
                  <div class="dot"></div>
                </div>`

        bubble.classList.add('bubble');
        bubble.innerHTML = div;
        let divId= questionid ? questionid : ''
        bubble.id=divId;
        msg.appendChild(bubble);
        chat.appendChild(msg);
        scrollToBottom();
        
        
        console.log(botMsg)
        
        console.log(bubble)
       }
       else
       {

        bubble.classList.add('bubble');
        let divId= questionid ? questionid : ''
        bubble.id=divId;
        msg.appendChild(bubble);
        chat.appendChild(msg);
        scrollToBottom();
        bubble.textContent=''
        if (typingEffect) {
          let index = 0;
          const interval = setInterval(() => {
            bubble.textContent += text.charAt(index);
            index++;
            scrollToBottom();
            if (index >= text.length) {
              clearInterval(interval);
              if (callback) callback();
            }
          }, 30);
        } else {
          bubble.textContent = text;
          if (callback) callback();
        }

       }
      // console.log(botMsg)
      // bubble.appendChild(botMsg);
      // console.log(bubble)



      // bubble.classList.add('bubble');
      // let divId= questionid ? questionid : ''
      // bubble.id=divId;
      // msg.appendChild(bubble);
      // chat.appendChild(msg);
      // scrollToBottom();
      // bubble.textContent=''
      // if (typingEffect) {
      //   let index = 0;
      //   const interval = setInterval(() => {
      //     bubble.textContent += text.charAt(index);
      //     index++;
      //     scrollToBottom();
      //     if (index >= text.length) {
      //       clearInterval(interval);
      //       if (callback) callback();
      //     }
      //   }, 30);
      // } else {
      //   bubble.textContent = text;
      //   if (callback) callback();
      // }
    }

    document.getElementById('start').onclick = async () => {
      const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
      socket = new WebSocket(`${protocol}//${location.host}`);
      socket.binaryType = 'arraybuffer';

      socket.onopen = async () => {
        audioContext = new AudioContext();
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        await audioContext.audioWorklet.addModule('processor.js');
        source = audioContext.createMediaStreamSource(mediaStream);
        processor = new AudioWorkletNode(audioContext, 'audio-capture');
        source.connect(processor).connect(audioContext.destination);

        processor.port.onmessage = (event) => {
          if (socket.readyState === WebSocket.OPEN) {
            socket.send(event.data);
          }
        };

        document.getElementById('start').disabled = true;
        document.getElementById('stop').disabled = false;
      };

      socket.onmessage = async (event) => {
        if (typeof event.data === 'string') {
          const data = JSON.parse(event.data);
          
           
            
          if (data.type === 'QnA') {
          // if (data.question != '')
          // {
          //   // üõë Stop any audio already playing 
          //   if (currentSource) {
          //     try {
          //       currentSource.stop();
          //       currentSource = null;
          //       audioQueue = [];
          //       isPlaying = false;
          //       console.log('üõë Previous audio stopped due to new response');
          //     } catch (e) {
          //       console.warn('Error stopping previous audio:', e.message);
          //     }
          //   }
          //     appendMessage(data.question, 'user');
          // }
            if (data.answer != '' )
              console.log(data);
              appendMessage(data.answer, 'agent',data.questionId, true, () => {
            
            });
          }
          else if (data.type === 'QnA_Pending') {
          if (data.question != '')
          {
            // üõë Stop any audio already playing 
            if (currentSource) {
              try {
                currentSource.stop();
                currentSource = null;
                audioQueue = [];
                isPlaying = false;
                console.log('üõë Previous audio stopped due to new response');
              } catch (e) {
                console.warn('Error stopping previous audio:', e.message);
              }
            }
              appendMessage(data.question, 'user');
              appendMessage('.....', 'agent',data.questionId , true, () => {});
          }
          }

          // if (data.type === 'ConversationText' && data.role === 'user') {
          //   alert(1);
          //   appendMessage(data.content, 'user');
          // }

          // if (data.type === 'ConversationText' && data.role === 'assistant') {
          //   alert(1);
          //   appendMessage(data.content, 'agent');
          // }
        } else {
          try {


            const buffer = event.data; // Already an ArrayBuffer
            audioQueue.push(buffer); // Add to queue
            playNextInQueue();       // Trigger playback if not already



            // const audioBuffer = await audioContext.decodeAudioData(event.data);
            // const sourceNode = audioContext.createBufferSource();
            // sourceNode.buffer = audioBuffer;
            // sourceNode.connect(audioContext.destination);
            // sourceNode.start();
          } catch (err) {
            console.warn('Audio decode/playback failed:', err.message);
          }
        }
      };

      socket.onclose = () => {
        appendMessage("üîå Disconnected from assistant.", 'agent');
        document.getElementById('start').disabled = false;
        document.getElementById('stop').disabled = true;
      };
    };
    async function playNextInQueue() {
  if (isPlaying || audioQueue.length === 0) return;

  isPlaying = true;
  const buffer = audioQueue.shift();

  try {
    if (audioContext.state === 'suspended') {
      await audioContext.resume();
    }

    const audioBuffer = await audioContext.decodeAudioData(buffer);
    const source = audioContext.createBufferSource();
    const gainNode = audioContext.createGain();
    gainNode.gain.value = 1.5;
    currentSource = source;
    source.buffer = audioBuffer;
    source.connect(gainNode).connect(audioContext.destination);

    source.onended = () => {
      isPlaying = false;
      playNextInQueue(); // Play next in line
    };

      source.start();
    } catch (e) {
      console.warn('Audio playback failed:', e.message);
      isPlaying = false;
      playNextInQueue(); // Try next
    }
  }
    document.getElementById('stop').onclick = () => {
      if (processor) processor.disconnect();
      if (source) source.disconnect();
      if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
      if (socket && socket.readyState === WebSocket.OPEN) socket.close();
    };
  </script>

</body>
</html>
